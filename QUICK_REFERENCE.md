# ðŸš€ Phase 3 Quick Reference

## Commands to Run

```bash
# Start server
python main.py

# Stop server
Ctrl + C in terminal
```

**URL:** http://127.0.0.1:7861

---

## UI Commands

| Command | Action |
|---------|--------|
| `Type question` | Generate SQL |
| `/schema` | Show current DB schema |
| `Use database <db_id>` | Switch database |
| **Regenerate SQL** button | Generate new SQL |
| **Run Query** button | Execute SQL |
| **Save Correction** button | Save edited SQL |

---

## Files & Locations

| File | Purpose |
|------|---------|
| `main.py` | Main application |
| `spider_eval.py` | Evaluation module |
| `spider/dev.json` | Spider dev set |
| `spider/database/` | 200+ databases |
| `chroma_db/` | Vectorstore cache |
| `interaction_log.jsonl` | Query logs |
| `saved_corrections.jsonl` | User corrections |
| `.env` | API keys |

---

## Configuration

```python
# In main.py lines 37-40:

USE_OPENAI = True              # True = OpenAI, False = Gemini
OPENAI_MODEL = "gpt-4o-mini"   # Options: gpt-4o-mini, gpt-4o
GEMINI_MODEL = "gemini-1.5-flash"  # Options: gemini-1.5-flash, gemini-1.5-pro
TEMPERATURE = 0.0              # 0.0 = deterministic, 0.7 = creative

# Database loading (line 215):
for i, (db_id, db_file) in enumerate(sorted(all_dbs.items())[:20]):  # Change 20 to load more

# Server port (line 912):
demo.launch(server_name='127.0.0.1', server_port=7861)  # Change 7861 if occupied
```

---

## Available Databases (Default 20)

1. activity_1
2. aircraft
3. allergy_1
4. apartment_rentals
5. architecture
6. assets_maintenance
7. behavior_monitoring
8. bike_1
9. body_builder
10. book_2
11. browser_web
12. candidate_poll
13. chinook_1
14. cinema
15. city_record
16. climbing
17. club_1
18. coffee_shop
19. (plus 182 more available)

---

## Key Functions

### Schema Extraction
```python
get_complete_schema_with_foreign_keys(db)
# Returns: Full schema with PKs, FKs, nullable info
```

### Table Selection
```python
select_relevant_tables(question, schema_text, llm)
# Returns: Top-5 relevant tables
```

### SQL Generation
```python
generate_sql(llm, vectorstore, databases, db_descriptions, 
             router_chain, db_list, question, db_id)
# Returns: Generated SQL string
```

### Evaluation
```python
spider_eval.evaluate_predictions(gold_file, pred_file, db_dir)
# Returns: {'exact_match': 0.72, 'execution_accuracy': 0.75, ...}
```

---

## Troubleshooting

| Problem | Solution |
|---------|----------|
| Port in use | Change `server_port=7861` to `7862` |
| Import errors | Install: `pip install -r requirements.txt` |
| API key error | Check `.env` file has `OPENAI_API_KEY=sk-...` |
| Slow startup | Reduce databases (change 20 to 10) |
| Out of memory | Reduce databases or increase RAM |
| Database not found | Type: `Use database <db_id>` |

---

## Evaluation Metrics

### Exact Match
- SQL strings match exactly (normalized)
- Target: 72-76%

### Execution Accuracy
- Results match when executed
- Usually 3-5% higher than exact match

---

## Project Structure

```
Dbms-project/
â”œâ”€â”€ main.py                 # 849 lines
â”œâ”€â”€ spider_eval.py          # Evaluation
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ .env                    # API keys (YOU CREATE)
â”œâ”€â”€ .gitignore             # Git exclusions
â”œâ”€â”€ PHASE3_README.md       # Full docs
â”œâ”€â”€ PHASE3_SUMMARY.md      # Implementation summary
â”œâ”€â”€ TESTING_GUIDE.md       # Test instructions
â”œâ”€â”€ QUICK_REFERENCE.md     # This file
â””â”€â”€ spider/                # Dataset (YOU DOWNLOAD)
```

---

## Sample Workflow

1. **Start:** `python main.py`
2. **Open:** http://127.0.0.1:7861
3. **Ask:** "Show all activities"
4. **Check:** SQL generated correctly
5. **Edit:** Modify SQL if needed
6. **Run:** Click Run Query button
7. **Save:** Click Save Correction
8. **Repeat:** Ask more questions
9. **Evaluate:** Go to Leaderboard tab
10. **Stats:** Check Statistics tab

---

## Phase 3 Features Checklist

- [x] Cross-schema support
- [x] Foreign key detection
- [x] Table pre-selection
- [x] Qualified name enforcement
- [x] Spider evaluation
- [x] Save corrections
- [x] 3-tab UI
- [x] Live statistics
- [x] HITL workflow
- [x] Production-ready

---

## Next Steps

1. âœ… Test with sample queries
2. âœ… Run evaluation (20-100 samples)
3. âœ… Save 5-10 corrections
4. âœ… Check statistics
5. âœ… Document your results
6. ðŸ“Š Present/Demo!

---

**Status:** Phase 3 Complete âœ…
**Target Accuracy:** 72-76% (with corrections)
**Production-Ready:** YES

---

Need help? Check:
- PHASE3_README.md (full documentation)
- TESTING_GUIDE.md (detailed test cases)
- PHASE3_SUMMARY.md (implementation details)
